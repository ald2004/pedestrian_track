import cv2
import os
import json
import time
import uuid
import numpy as np
import sqlite3
from multiprocessing import Process
from api.CameraApi import (
    get_ins,
    start
)
import multiprocessing
import threading
from multiprocessing import Process, Queue
import ffmpeg
from api.convertimg import gen_camera_frame
import fire
from api.yolo_reid_pint_api import YoloReidPintAPIAlgorithm as pint_api
from api.yolo_reid_pint_api import Config
from api.yolo_reid_pint_api import cosine_distance
from api.plot_utils import plot_multi_images
from api.timer import Timer
import sqlite3

IMAGE_PIPE = '/dev/shm/img_q'
RTMP_PIPE = '/dev/shm/rtmp_q'
w = 640
h = 480
c = 3


# class Config():
#     def __init__(self, json_path=None):
#         self.config = {}
#         with open(json_path, "r", encoding='utf-8') as f:
#             self.config = json.loads(f.read())
#         self.config['FIFO'] = '/dev/shm/img_q'
#         self.config['w'] = 640
#         self.config['h'] = 480
#         self.config['c'] = 3


class demo_classer(object):
    def __init__(self):
        with open("./config/yolo_reid_config.json", "r", encoding='utf-8') as f:
            self.config = json.loads(f.read())
        self.model = pint_api(self.config)
        self.timer = Timer()
        self.config['FIFO'] = '/dev/shm/img_q'
        self.config['w'] = 640
        self.config['h'] = 480
        self.config['c'] = 3
        self.config['RTMP_PATH'] = 'rtmp://192.168.8.121/live/bbb'
        self.conn = sqlite3.connect('aquarium.db')
        self.c = self.conn.cursor()

    def result_to_db(self, f, b, d):
        if not len(b):
            return
        # f (128,)
        # b [[183, 163, 484, 317], [52, 121, 38, 48], [13, 124, 46, 70], [12, 172, 41, 40], [401, 172, 46, 84], [224, 280, 202, 193]]
        # d
        # [
        #     {'box': array([0.28747933, 0.34066093, 1.04517841, 1.00288587]), 'class_name': 'person',
        #      'score': 0.99528664, 'class_id': 0},
        #     {'box': array([0.0814497, 0.25219855, 0.14155266, 0.35405122]), 'class_name': 'person', 'score': 0.9562466,
        #      'class_id': 0},
        #     {'box': array([0.02163462, 0.2603192, 0.09375, 0.40695381]), 'class_name': 'person', 'score': 0.78090733,
        #      'class_id': 0},
        #     {'box': array([0.01887899, 0.35872319, 0.08315149, 0.44294513]), 'class_name': 'person',
        #      'score': 0.64942235, 'class_id': 0},
        #     {'box': array([0.62744258, 0.35946582, 0.69955796, 0.53540744]), 'class_name': 'person',
        #      'score': 0.36657786, 'class_id': 0},
        #     {'box': array([0.35106538, 0.58400088, 0.66795829, 0.98621112]), 'class_name': 'chair', 'score': 0.62029713,
        #      'class_id': 56}
        # ]
        # filename = f"/dev/shm/{uuid.uuid4().hex}"
        filename = f"/dev/shm/{time.time()}"
        np.savez_compressed(filename, allow_pickle=True, f=f, b=b, d=d)
        # with open('/dev/shm/result_tmp_txt','w') as fid:
        #     fid.writelines([str(a) for a in f])
        #     fid.write("="*100)
        #     fid.writelines([str(a) for a in b])
        #     fid.write("=" * 100)
        #     fid.writelines([str(a) for a in d])

    def pint_main(self, q: Queue, outq: Queue, detstatisq: Queue):
        # imgs_list = ['./images/boe_test.jpg', ]
        # print(config)

        # imgs = []
        # for img_path in imgs_list:
        #     img = cv2.imread(img_path)
        #     imgs.append(img)

        # get config
        # model = pint_api(self.config)
        # get frame
        # while not os.path.exists(self.config['FIFO']):
        #     print(f'wait for frame pipe : {self.config["FIFO"]}')
        #     time.sleep(1)
        # # for _ in range(10):
        # # while 1:
        xor = 0
        # outfifo = open('/dev/shm/rtmp_q', 'wb')
        # with open(self.config['FIFO'], 'rb') as fifo:
        # cap = cv2.VideoCapture(0)
        while 1:
            # data = fifo.read(self.config['w'] * self.config['h'] * self.config['c'])
            # print(f'len of data is :{len(data)}')
            # xor += 1
            # if xor != 3:
            #     continue
            # xor = 0
            # f, img = cap.read()
            try:
                img: np.ndarray = q.get()
            except:
                time.sleep(.2)
                continue
            features, boxes, detect_result = self.model.run([img])
            try:
                detstatisq.put((features, boxes, detect_result))

            except:
                print(f"detstatisq err {features, boxes, detect_result}")
            # xor += 1
            # if not (xor - 3):
            #     # self.result_to_db(features, boxes, detect_result)
            #     xor = 0
            # plot_multi_images([img], detect_result)

            # ret2, frame2 = cv2.imencode('.png', img)
            # outq.put(img)
            outq.put(detect_result)
            # if len(data):
            # if f:
            # buff = np.frombuffer(data, np.uint8)
            # imgx = cv2.imdecode(buff, cv2.IMREAD_COLOR)
            # img = cv2.resize(imgx, (320,240))
            # features, boxes, detect_result = model.run([img])
            #
            # if detect_result:
            #     plot_multi_images([img], detect_result)
            # else :
            #     _, _, detect_result = model.run([img])
            #     plot_multi_images([img], detect_result)
            # ret2, frame2 = cv2.imencode('.png', imgx)
            # outfifo.write(frame2)
            # ffmpegprocess.stdin.write(frame2.tobytes())
            # print("#" * 40)
            # print(features)
            # print("#" * 40)
            # print(boxes)
            # print("#" * 40)
            # print(detect_result)
            # print("#" * 40)
            # dist = cosine_distance(features[0][0], features[0][1])
            # print(len(features[0]), len(features[0][0]))
            # print(dist)

            # cv2.imwrite(f'/dev/shm/detection_result_{uuid.uuid4().hex}.jpg', img)

            # print("the merge vision run time is {:.2f} ms".format((end - start) * 1000))
            # else:
            #     print('data is none')


def get_camera_frame(_):
    print('=' * 60)
    print(f'start get camera frame with process :{Process.name}')
    print('=' * 60)
    spam = get_ins()
    start(spam)


def pintmain(q, outq, detstatisq):
    xx = demo_classer()
    xx.pint_main(q, outq, detstatisq)


def p_getframe_python_to_queue(q: Queue):
    with open(IMAGE_PIPE, 'rb') as fifo:
        print("FIFO opened")
        while True:
            # image_stream = io.BytesIO()
            data = fifo.read(w * h * c)
            if not len(data):
                continue

            buff = np.frombuffer(data, np.uint8)
            imgx = cv2.imdecode(buff, cv2.IMREAD_COLOR)
            try:
                q.put(imgx)
            except:
                print('q full')
                try:
                    for _ in range(20):
                        q.get_nowait()
                except:
                    pass
    # cap = cv2.VideoCapture(0)
    # while 1:
    #     f, i = cap.read()
    #     if f:
    #         try:
    #             q.put(i)
    #         except:
    #             print('q full')
    #             try:
    #                 for _ in range(200):
    #                     q.get_nowait()
    #             except:
    #                 pass


def p_putframe_python_to_pipe(q: Queue, outq: Queue):
    while not os.path.exists(RTMP_PIPE):
        print(f'wait for frame pipe : {RTMP_PIPE}')
        time.sleep(1)

    def put_real_stream(outfifo, q):
        while 1:
            try:
                i = q.get()
                ret2, frame2 = cv2.imencode('.png', i)
                outfifo.write(frame2)
            except:
                time.sleep(.5)
                print(f'none q img')

    def put_det_stream(outfifo, outq, realq):
        while 1:
            # outi = outq.get()
            detect_result = outq.get()
            img = realq.get()
            plot_multi_images([img], detect_result)

            ret2, frame3 = cv2.imencode('.png', img)
            outfifo.write(frame3)

    with open(RTMP_PIPE, 'wb') as outfifo:
        t1 = threading.Thread(target=put_real_stream, args=(outfifo, q))
        t2 = threading.Thread(target=put_det_stream, args=(outfifo, outq, q))
        t1.start()
        t2.start()
        while 1:
            time.sleep(99)
        # while 1:
        #     outi = outq.get()
        #     ret2, frame3 = cv2.imencode('.png', outi)
        #     outfifo.write(frame3)
        # try:
        #     outi=outq.get()
        #     ret2, frame3 = cv2.imencode('.png', outi)
        #     outfifo.write(frame3)
        # except:
        #     pass
        # try:
        #     i = q.get()
        #     ret2, frame2 = cv2.imencode('.png', i)
        #     outfifo.write(frame2)
        # except:
        #     time.sleep(.5)
        #     print(f'none q img')

def statis_to_ws(detsq:Queue):
    while 1:
        f,b,d = detsq.get()
        print('*'*88)
        print(type(f),type(b),type(d))
        print('*' * 88)
        os._exit(0)

if __name__ == "__main__":
    # process = (
    #     ffmpeg
    #         .input('pipe:', r='6', hwaccel='vdpau', hwaccel_device='/dev/dri/card0')
    #         .output('rtmp://192.168.8.121/live/bbb', vcodec='libx264', pix_fmt='yuv420p', preset='veryfast',
    #                 r='20', g='50', video_bitrate='1.4M', maxrate='2M', bufsize='2M', segment_time='6',
    #                 format='flv',
    #                 #**{'c:v': 'h264_rkmpp'}
    #                 )
    #         .run_async(pipe_stdin=True))

    q = Queue(maxsize=20)
    outq = Queue(maxsize=20)
    detstatisq = Queue()

    gcf = Process(target=get_camera_frame, args=(None,))
    pm = Process(target=pintmain, args=(q, outq, detstatisq))
    gcf.start()
    # gci = Process(target=gen_camera_frame,args=(None,))
    gcq = Process(target=p_getframe_python_to_queue, args=(q,))
    gpq = Process(target=p_putframe_python_to_pipe, args=(q, outq))
    gcq.start()
    gpq.start()
    pm.start()

    statisprocess = Process(target=statis_to_ws, args=(detstatisq,))
    statisprocess.start()
    # fire.Fire(demo_classer)
    # gcf.join()
    # pm.join()
    while 1:
        time.sleep(30)
'''
 ffmpeg -hwaccel_device /dev/dri/card0 -r 9 -i /dev/shm/rtmp_q -an -s 320*240  -f flv -r 9 rtmp://192.168.8.121/live/bbb -c:v h264_vaapi
  ffmpeg -hwaccel_device /dev/dri/card0 -r 9 -i /dev/shm/rtmp_q -an -s 320*240  -f flv -r 9 rtmp://192.168.8.121/live/bbb -c:v hevc_vaapi
'''
